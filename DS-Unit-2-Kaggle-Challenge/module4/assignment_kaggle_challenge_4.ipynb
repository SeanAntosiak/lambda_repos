{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lambda School Data Science, Unit 2: Predictive Modeling\n",
    "\n",
    "# Kaggle Challenge, Module 4\n",
    "\n",
    "## Catch up, if needed\n",
    "- [Review requirements for your portfolio project](https://lambdaschool.github.io/ds/unit2/portfolio-project/ds6), then choose your dataset, and [submit this form](https://forms.gle/nyWURUg65x1UTRNV9), due yesterday at 3:59pm Pacific.\n",
    "- Submit predictions to our Kaggle competition. (Go to our Kaggle InClass competition webpage. Use the blue **Submit Predictions** button to upload your CSV file.) The competition closes today at 3:59pm. Every student should make at least one submission that scores at least 60% accuracy (above the majority class baseline).\n",
    "\n",
    "## Assignment\n",
    "- [ ] Continue to participate in our Kaggle challenge. \n",
    "- [ ] Use scikit-learn for hyperparameter optimization with RandomizedSearchCV.\n",
    "- [ ] Submit your final predictions to our Kaggle competition. Optionally, go to **My Submissions**, and _\"you may select up to 1 submission to be used to count towards your final leaderboard score.\"_ The competition closes today at 3:59pm.\n",
    "- [ ] Add comments and Markdown to your notebook. Clean up your code.\n",
    "- [ ] Commit your notebook to your fork of the GitHub repo.\n",
    "\n",
    "## Stretch Goals\n",
    "\n",
    "### Reading\n",
    "- Jake VanderPlas, [Python Data Science Handbook, Chapter 5.3](https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html), Hyperparameters and Model Validation\n",
    "- Jake VanderPlas, [Statistics for Hackers](https://speakerdeck.com/jakevdp/statistics-for-hackers?slide=107)\n",
    "- Ron Zacharski, [A Programmer's Guide to Data Mining, Chapter 5](http://guidetodatamining.com/chapter5/), 10-fold cross validation\n",
    "- Sebastian Raschka, [A Basic Pipeline and Grid Search Setup](https://github.com/rasbt/python-machine-learning-book/blob/master/code/bonus/svm_iris_pipeline_and_gridsearch.ipynb)\n",
    "- Peter Worcester, [A Comparison of Grid Search and Randomized Search Using Scikit Learn](https://blog.usejournal.com/a-comparison-of-grid-search-and-randomized-search-using-scikit-learn-29823179bc85)\n",
    "\n",
    "### Doing\n",
    "- Try combining xgboost early stopping, cross-validation, & hyperparameter optimization, with [the \"original\" (non scikit-learn) xgboost API](https://xgboost.readthedocs.io/en/latest/python/python_api.html#xgboost.cv).\n",
    "- In additon to `RandomizedSearchCV`, scikit-learn has [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Another library called scikit-optimize has [`BayesSearchCV`](https://scikit-optimize.github.io/notebooks/sklearn-gridsearchcv-replacement.html). Experiment with these alternatives.\n",
    "- _[Introduction to Machine Learning with Python](http://shop.oreilly.com/product/0636920030515.do)_ discusses options for \"Grid-Searching Which Model To Use\" in Chapter 6:\n",
    "\n",
    "> You can even go further in combining GridSearchCV and Pipeline: it is also possible to search over the actual steps being performed in the pipeline (say whether to use StandardScaler or MinMaxScaler). This leads to an even bigger search space and should be considered carefully. Trying all possible solutions is usually not a viable machine learning strategy. However, here is an example comparing a RandomForestClassifier and an SVC ...\n",
    "\n",
    "The example is shown in [the accompanying notebook](https://github.com/amueller/introduction_to_ml_with_python/blob/master/06-algorithm-chains-and-pipelines.ipynb), code cells 35-37. Could you apply this concept to your own pipelines?\n",
    "\n",
    "#### Try stacking multiple submissions!\n",
    "\n",
    "Here's some code you can use:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Filenames of your submissions you want to ensemble\n",
    "files = ['submission-01.csv', 'submission-02.csv', 'submission-03.csv']\n",
    "\n",
    "target = 'status_group'\n",
    "submissions = (pd.read_csv(file)[[target]] for file in files)\n",
    "ensemble = pd.concat(submissions, axis='columns')\n",
    "majority_vote = ensemble.mode(axis='columns')[0]\n",
    "\n",
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "submission = sample_submission.copy()\n",
    "submission[target] = majority_vote\n",
    "submission.to_csv('my-ultimate-ensemble-submission.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import category_encoders as ce\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "from scipy.stats import randint, uniform\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates dataframes for each file\n",
    "\n",
    "test0 = pd.read_csv('https://raw.githubusercontent.com/SeanAntosiak/DS-Unit-2-Regression-Classification/master/data/tanzania/test_features.csv')\n",
    "train0 = pd.read_csv('https://raw.githubusercontent.com/SeanAntosiak/DS-Unit-2-Regression-Classification/master/data/tanzania/train_features.csv')\n",
    "trainLabels = pd.read_csv('https://raw.githubusercontent.com/SeanAntosiak/DS-Unit-2-Regression-Classification/master/data/tanzania/train_labels.csv')\n",
    "sample = pd.read_csv('https://raw.githubusercontent.com/SeanAntosiak/DS-Unit-2-Regression-Classification/master/data/tanzania/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs a train test split to create train and validation data\n",
    "\n",
    "Xtrain0, Xval0, ytrain0, yval0 = tts(train0, trainLabels['status_group'], train_size=0.85, test_size=0.15, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a function to wrangle data\n",
    "\n",
    "def wrangle(DF):\n",
    "    \n",
    "    # creates a copy of the input dataframe\n",
    "    df = DF.copy()\n",
    "                    \n",
    "    # converts date_recorded to a year\n",
    "    df['date_recorded'] = pd.to_datetime(df['date_recorded'], infer_datetime_format=True).dt.year\n",
    "    \n",
    "    # defines the columns which apear to have missing values input as 0\n",
    "    zeroCols = ['amount_tsh', 'longitude', 'latitude', 'gps_height', 'construction_year']\n",
    "    \n",
    "     # replaces tiny latitude values with 0 to be replaced with nan in the next step \n",
    "    df['latitude']=df['latitude'].replace(-2e-8,0)\n",
    "    \n",
    "    # replaces missing 0 values with nan\n",
    "    for col in zeroCols:\n",
    "        df[col] = df[col].replace(0, np.nan)\n",
    "        df[col+'_missing']=df[col].isnull();\n",
    "       \n",
    "        \n",
    "    return(df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applies wrangle function to each dataframe\n",
    "\n",
    "Xtrain = wrangle(Xtrain0)\n",
    "Xval = wrangle(Xval0)\n",
    "Xtest = wrangle(test0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates a pipeline for a random forrest regressor then scores it with cross score validation\n",
    "\n",
    "pipe0 = make_pipeline(\n",
    "            ce.OrdinalEncoder(), \n",
    "            SimpleImputer(),\n",
    "            MinMaxScaler(),     \n",
    "            RandomForestClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8023569023569024"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits pipeline and scores it\n",
    "\n",
    "pipe0.fit(Xtrain, ytrain0)\n",
    "\n",
    "pipe0.score(Xval, yval0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = RandomizedSearchCV(\n",
    "            pipe0,\n",
    "            param_distributions = {\n",
    "            'simpleimputer__strategy':['mean','median','most_frequent'],\n",
    "            'randomforestclassifier__n_estimators': randint(10,100), # I am running into memory errors if this value is higher\n",
    "            'randomforestclassifier__max_depth': [5, 10, 15, 20], \n",
    "            'randomforestclassifier__max_features': uniform(0, 1)\n",
    "            },\n",
    "        n_iter=5,\n",
    "        cv=3,\n",
    "        return_train_score=True,\n",
    "        n_jobs=-1\n",
    ")\n",
    "\n",
    "search.fit(Xtrain, ytrain0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_randomforestclassifier__max_depth</th>\n",
       "      <th>param_randomforestclassifier__max_features</th>\n",
       "      <th>param_randomforestclassifier__n_estimators</th>\n",
       "      <th>param_simpleimputer__strategy</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.633264</td>\n",
       "      <td>0.043811</td>\n",
       "      <td>0.536534</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>20</td>\n",
       "      <td>0.244742</td>\n",
       "      <td>61</td>\n",
       "      <td>median</td>\n",
       "      <td>{'randomforestclassifier__max_depth': 20, 'ran...</td>\n",
       "      <td>0.801973</td>\n",
       "      <td>0.800368</td>\n",
       "      <td>0.805324</td>\n",
       "      <td>0.802555</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>1</td>\n",
       "      <td>0.973410</td>\n",
       "      <td>0.974004</td>\n",
       "      <td>0.974719</td>\n",
       "      <td>0.974044</td>\n",
       "      <td>0.000535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.747514</td>\n",
       "      <td>1.518296</td>\n",
       "      <td>0.371462</td>\n",
       "      <td>0.021300</td>\n",
       "      <td>20</td>\n",
       "      <td>0.598392</td>\n",
       "      <td>81</td>\n",
       "      <td>median</td>\n",
       "      <td>{'randomforestclassifier__max_depth': 20, 'ran...</td>\n",
       "      <td>0.799002</td>\n",
       "      <td>0.799834</td>\n",
       "      <td>0.802234</td>\n",
       "      <td>0.800357</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>2</td>\n",
       "      <td>0.965923</td>\n",
       "      <td>0.964675</td>\n",
       "      <td>0.965718</td>\n",
       "      <td>0.965439</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.626476</td>\n",
       "      <td>0.163416</td>\n",
       "      <td>0.477811</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>15</td>\n",
       "      <td>0.290425</td>\n",
       "      <td>50</td>\n",
       "      <td>median</td>\n",
       "      <td>{'randomforestclassifier__max_depth': 15, 'ran...</td>\n",
       "      <td>0.797398</td>\n",
       "      <td>0.792942</td>\n",
       "      <td>0.800749</td>\n",
       "      <td>0.797029</td>\n",
       "      <td>0.003198</td>\n",
       "      <td>3</td>\n",
       "      <td>0.897947</td>\n",
       "      <td>0.890698</td>\n",
       "      <td>0.891480</td>\n",
       "      <td>0.893375</td>\n",
       "      <td>0.003249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27.773251</td>\n",
       "      <td>0.443891</td>\n",
       "      <td>0.559022</td>\n",
       "      <td>0.012275</td>\n",
       "      <td>15</td>\n",
       "      <td>0.786308</td>\n",
       "      <td>87</td>\n",
       "      <td>median</td>\n",
       "      <td>{'randomforestclassifier__max_depth': 15, 'ran...</td>\n",
       "      <td>0.790209</td>\n",
       "      <td>0.789317</td>\n",
       "      <td>0.794212</td>\n",
       "      <td>0.791246</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>4</td>\n",
       "      <td>0.890579</td>\n",
       "      <td>0.880507</td>\n",
       "      <td>0.883608</td>\n",
       "      <td>0.884898</td>\n",
       "      <td>0.004212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.620033</td>\n",
       "      <td>0.018346</td>\n",
       "      <td>0.375247</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>10</td>\n",
       "      <td>0.447509</td>\n",
       "      <td>31</td>\n",
       "      <td>median</td>\n",
       "      <td>{'randomforestclassifier__max_depth': 10, 'ran...</td>\n",
       "      <td>0.764304</td>\n",
       "      <td>0.759194</td>\n",
       "      <td>0.762123</td>\n",
       "      <td>0.761874</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>5</td>\n",
       "      <td>0.790903</td>\n",
       "      <td>0.788586</td>\n",
       "      <td>0.786733</td>\n",
       "      <td>0.788740</td>\n",
       "      <td>0.001706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       8.633264      0.043811         0.536534        0.001811   \n",
       "4      16.747514      1.518296         0.371462        0.021300   \n",
       "2       7.626476      0.163416         0.477811        0.003329   \n",
       "1      27.773251      0.443891         0.559022        0.012275   \n",
       "3       5.620033      0.018346         0.375247        0.011620   \n",
       "\n",
       "  param_randomforestclassifier__max_depth  \\\n",
       "0                                      20   \n",
       "4                                      20   \n",
       "2                                      15   \n",
       "1                                      15   \n",
       "3                                      10   \n",
       "\n",
       "  param_randomforestclassifier__max_features  \\\n",
       "0                                   0.244742   \n",
       "4                                   0.598392   \n",
       "2                                   0.290425   \n",
       "1                                   0.786308   \n",
       "3                                   0.447509   \n",
       "\n",
       "  param_randomforestclassifier__n_estimators param_simpleimputer__strategy  \\\n",
       "0                                         61                        median   \n",
       "4                                         81                        median   \n",
       "2                                         50                        median   \n",
       "1                                         87                        median   \n",
       "3                                         31                        median   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'randomforestclassifier__max_depth': 20, 'ran...           0.801973   \n",
       "4  {'randomforestclassifier__max_depth': 20, 'ran...           0.799002   \n",
       "2  {'randomforestclassifier__max_depth': 15, 'ran...           0.797398   \n",
       "1  {'randomforestclassifier__max_depth': 15, 'ran...           0.790209   \n",
       "3  {'randomforestclassifier__max_depth': 10, 'ran...           0.764304   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.800368           0.805324         0.802555        0.002065   \n",
       "4           0.799834           0.802234         0.800357        0.001370   \n",
       "2           0.792942           0.800749         0.797029        0.003198   \n",
       "1           0.789317           0.794212         0.791246        0.002129   \n",
       "3           0.759194           0.762123         0.761874        0.002093   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.973410            0.974004   \n",
       "4                2            0.965923            0.964675   \n",
       "2                3            0.897947            0.890698   \n",
       "1                4            0.890579            0.880507   \n",
       "3                5            0.790903            0.788586   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.974719          0.974044         0.000535  \n",
       "4            0.965718          0.965439         0.000546  \n",
       "2            0.891480          0.893375         0.003249  \n",
       "1            0.883608          0.884898         0.004212  \n",
       "3            0.786733          0.788740         0.001706  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(search.cv_results_).sort_values(by='rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
