{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 4 Sprint 3 Assignment 2*\n",
    "# Convolutional Neural Networks (CNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0lfZdD_cp1t5"
   },
   "source": [
    "# Assignment\n",
    "\n",
    "Load a pretrained network from Keras, [ResNet50](https://tfhub.dev/google/imagenet/resnet_v1_50/classification/1) - a 50 layer deep network trained to recognize [1000 objects](https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt). Starting usage:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "ResNet50 = ResNet50(weights='imagenet')\n",
    "features = model.predict(x)\n",
    "\n",
    "```\n",
    "\n",
    "Next you will need to remove the last layer from the ResNet model. Here, we loop over the layers to use the sequential API. There are easier ways to add and remove layers using the Keras functional API, but doing so introduces other complexities. \n",
    "\n",
    "```python\n",
    "# Remote the Last Layer of ResNEt\n",
    "ResNet50._layers.pop(0)\n",
    "\n",
    "# Out New Model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Pre-trained layers of Old Model to New Model\n",
    "for layer in ResNet50.layers:\n",
    "    model.add(layer)\n",
    "\n",
    "# Turn off additional training of ResNet Layers for speed of assignment\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add New Output Layer to Model\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "```\n",
    "\n",
    "Your assignment is to apply the transfer learning above to classify images of Mountains (`./data/mountain/*`) and images of forests (`./data/forest/*`). Treat mountains as the postive class (1) and the forest images as the negative (zero). \n",
    "\n",
    "Steps to complete assignment: \n",
    "1. Load in Image Data into numpy arrays (`X`) \n",
    "2. Create a `y` for the labels\n",
    "3. Train your model with pretrained layers from resnet\n",
    "4. Report your model's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# brings in picture data\n",
    "forests = []\n",
    "for pic in os.listdir('./data/forest/'):\n",
    "    forests.append(np.array(image.load_img(path=f'./data/forest/{pic}',\n",
    "                                          color_mode='rgb', \n",
    "                                          target_size=(224,224)\n",
    "                                          )))\n",
    "    \n",
    "mountains = []\n",
    "for pic in os.listdir('./data/mountain/'):\n",
    "    mountains.append(np.array(image.load_img(path=f'./data/mountain/{pic}',\n",
    "                                            color_mode='rgb', \n",
    "                                            target_size=(224,224)\n",
    "                                            )))\n",
    "    \n",
    "forests = np.array(forests)\n",
    "\n",
    "mountains = np.array(mountains)\n",
    "\n",
    "# creates x variable from pictures\n",
    "x0 = np.append(forests, mountains, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates y variables for pictures\n",
    "y_forests = np.zeros((forests.shape[0], 1))\n",
    "\n",
    "y_mountains = np.ones((mountains.shape[0], 1))\n",
    "\n",
    "# creatse y variable\n",
    "y0 = np.append(y_forests, y_mountains, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts values to float for model\n",
    "\n",
    "x0 = x0.astype(float)\n",
    "y0 = y0.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffels data so mountain and forest is mixed\n",
    "x, y = shuffle(x0, y0)\n",
    "\n",
    "# perfroms train test split on data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and defines input shape\n",
    "resnet = ResNet50(input_shape=(224, 224, 3), \n",
    "                  weights='imagenet', \n",
    "                  include_top=False)\n",
    "\n",
    "# makes layers untrainable\n",
    "for layer in resnet.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "# creates model\n",
    "resnet_output = resnet.output\n",
    "flat = Flatten()(resnet_output) # Flattens output to 1 value\n",
    "predictions = Dense(1, activation='sigmoid')(flat)\n",
    "mod = Model(resnet.input, predictions)\n",
    "mod.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 631 samples\n",
      "631/631 [==============================] - 33s 52ms/sample - loss: 0.6869 - accuracy: 0.9002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f21ba43feb8>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fits model to train last trainable layer\n",
    "mod.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9154929518699646\n"
     ]
    }
   ],
   "source": [
    "score = mod.evaluate(x_test, y_test, verbose=0)\n",
    "print(f'accuracy = {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uT3UV3gap9H6"
   },
   "source": [
    "# Resources and Stretch Goals\n",
    "\n",
    "Stretch goals\n",
    "- Enhance your code to use classes/functions and accept terms to search and classes to look for in recognizing the downloaded images (e.g. download images of parties, recognize all that contain balloons)\n",
    "- Check out [other available pretrained networks](https://tfhub.dev), try some and compare\n",
    "- Image recognition/classification is somewhat solved, but *relationships* between entities and describing an image is not - check out some of the extended resources (e.g. [Visual Genome](https://visualgenome.org/)) on the topic\n",
    "- Transfer learning - using images you source yourself, [retrain a classifier](https://www.tensorflow.org/hub/tutorials/image_retraining) with a new category\n",
    "- (Not CNN related) Use [piexif](https://pypi.org/project/piexif/) to check out the metadata of images passed in to your system - see if they're from a national park! (Note - many images lack GPS metadata, so this won't work in most cases, but still cool)\n",
    "\n",
    "Resources\n",
    "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385) - influential paper (introduced ResNet)\n",
    "- [YOLO: Real-Time Object Detection](https://pjreddie.com/darknet/yolo/) - an influential convolution based object detection system, focused on inference speed (for applications to e.g. self driving vehicles)\n",
    "- [R-CNN, Fast R-CNN, Faster R-CNN, YOLO](https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e) - comparison of object detection systems\n",
    "- [Common Objects in Context](http://cocodataset.org/) - a large-scale object detection, segmentation, and captioning dataset\n",
    "- [Visual Genome](https://visualgenome.org/) - a dataset, a knowledge base, an ongoing effort to connect structured image concepts to language"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
